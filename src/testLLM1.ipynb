{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e74a20-038f-40b5-86ec-b94709f34635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishani/anaconda3/envs/rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-13 16:09:16,323 - INFO - Use pytorch device_name: mps\n",
      "2025-03-13 16:09:16,323 - INFO - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<function mistral_local at 0x12394a680>, model='mistral:latest', temperature=0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
      "2025-03-13 16:09:22,595 - INFO - Embedding generated in 0.186 seconds\n",
      "2025-03-13 16:09:22,638 - INFO - Vector search completed in 0.043 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text:  Game state: Score 19, 3 collisions,\n",
      "4 seconds left.\n",
      "User state: Stress medium, trust low, cognitive load medium.\n",
      "Task: Understanding AI's latest decision\n",
      "\n",
      "Query embedding:  1024\n",
      "   stress   trust cognitive_load  game_score  num_collisions  time_left  \\\n",
      "0  medium     low         medium          19               3        4.0   \n",
      "1  medium     low         medium          19               3        NaN   \n",
      "2  medium  medium         medium          45               5        NaN   \n",
      "3  medium     low           high          50               0        NaN   \n",
      "\n",
      "                     task_description                                    id  \\\n",
      "0  Understanding AI's latest decision                                   NaN   \n",
      "1                                 NaN  058f4dd8-fce8-11ef-9895-795ee886a8f8   \n",
      "2                                 NaN  112a4c56-fce8-11ef-abb3-c992f7f4e08a   \n",
      "3                                 NaN  0df327e2-fce8-11ef-a312-12bb33a01df4   \n",
      "\n",
      "                                             content  distance  \\\n",
      "0                                                NaN       NaN   \n",
      "1  Game state: Score 19, 3 collisions,\\n4 seconds...  0.078029   \n",
      "2  Game state: Score 45, 5 collisions,\\n34 second...  0.084518   \n",
      "3  Game state: Score 50, 0 collisions,\\n22 second...  0.089126   \n",
      "\n",
      "                   created_at  \n",
      "0                         NaN  \n",
      "1  2025-03-10T00:11:32.766619  \n",
      "2  2025-03-10T00:11:52.237231  \n",
      "3  2025-03-10T00:11:46.842693  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:09:31,711 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:31,884 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:32,065 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate samples: 9.425166130065918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:09:42,071 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:42,224 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:43,304 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- new_ys --: (' AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load).', ' \"AI prioritized fewer collisions to improve score (3 vs 5).\"', ' AI prioritizes serving orders quickly (decrease score) due to high collisions (3). Simplifying routes may help reduce mistakes.')\n",
      "-- sol values --: (2, 0, 0)\n",
      "-- choices --: [' AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load).']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:09:52,055 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:52,554 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:09:55,042 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate samples: 11.732892990112305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:10:06,522 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:06,656 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:08,457 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- new_ys --: (\" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load).\", ' AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Yes, the assistant has enough context.\\nExplanation: \"Serving quickly to meet deadline (low score, time_pressure)\".', ' AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Yes, the assistant has enough context.\\n\\nExplanation: AI prioritizes serving orders quickly (low score, high time pressure) to improve performance (medium stress, medium cognitive load, low trust).')\n",
      "-- sol values --: (2, 0, 0)\n",
      "-- choices --: [\" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load).\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:10:17,975 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:18,615 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:18,794 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate samples: 10.334681034088135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:10:33,778 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:34,547 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 16:10:35,714 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- new_ys --: (\" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load). Yes, the assistant has enough context.\\n\\nExplanation: AI prioritizes serving order for higher score (19) under high time pressure (4 sec left), to reduce collisions (3).\", \" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load). AI prioritizes serving order for higher score in limited time (stress, low trust).\", \" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load). Yes, the assistant has enough context.\\n\\nExplanation: AI prioritizes serving quickly due to low score and time pressure (stress, high cognitive load).\")\n",
      "-- sol values --: (2, 0, 0)\n",
      "-- choices --: [\" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load). Yes, the assistant has enough context.\\n\\nExplanation: AI prioritizes serving order for higher score (19) under high time pressure (4 sec left), to reduce collisions (3).\"]\n",
      "\n",
      "\n",
      "-- final choices --: [\" AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\\n     1. Identify user's medium stress, low trust, and medium cognitive load.\\n     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\\n     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\\n     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\\n\\n   Explanation:\\n     AI serves quickly due to low score & time pressure (stress, cognitive load). Yes, the assistant has enough context.\\n\\nExplanation: AI prioritizes serving order for higher score (19) under high time pressure (4 sec left), to reduce collisions (3).\"]\n",
      "\n",
      " AI chose to serve the waiting order quickly due to low score and high time pressure (stress, cognitive load). Explanation Plan:\n",
      "     1. Identify user's medium stress, low trust, and medium cognitive load.\n",
      "     2. Recognize task behavioral State with a low score, 3 collisions, and 4 seconds left.\n",
      "     3. Select an explanation style that focuses on clarity, justification, and simplicity (low trust, high cognitive load).\n",
      "     4. Adjust wording to focus on the AI's decision based on the game conditions (score, time pressure).\n",
      "\n",
      "   Explanation:\n",
      "     AI serves quickly due to low score & time pressure (stress, cognitive load). Yes, the assistant has enough context.\n",
      "\n",
      "Explanation: AI prioritizes serving order for higher score (19) under high time pressure (4 sec left), to reduce collisions (3).\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from tot.methods.bfs import solve\n",
    "from tot.tasks.adax import AdaXTask\n",
    "\n",
    "args = argparse.Namespace(backend='mistral:latest', temperature=0.7, task='adax', naive_run=False, prompt_sample=\"cot\", method_generate='sample', method_evaluate='vote', method_select='greedy', n_generate_sample=3, n_evaluate_sample=3, n_select_sample=1)\n",
    "\n",
    "task = AdaXTask()\n",
    "ys, infos = solve(args, task, 0)\n",
    "print(ys[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
